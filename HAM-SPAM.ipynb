{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, we'll develop a classifier that distinguishes between \"ham\" (legitimate) and \"spam\" (unsolicited) messages. The ability to classify messages accurately is essential for various applications such as email filtering, SMS filtering, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/p/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score,make_scorer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141</th>\n",
       "      <td>spam</td>\n",
       "      <td>\"This is the 2nd time we have tried 2 contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will �_ b going to esplanade fr home?,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11143</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Pity, * was in mood for that. So...any othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11144</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11145</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            message\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "11141  spam    \"This is the 2nd time we have tried 2 contac...\n",
       "11142   ham           Will �_ b going to esplanade fr home?,,,\n",
       "11143   ham    \"Pity, * was in mood for that. So...any othe...\n",
       "11144   ham    The guy did some bitching but I acted like i...\n",
       "11145   ham                      Rofl. Its true to its name,,,\n",
       "\n",
       "[11146 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in os.listdir('./smsspamcollection/'):\n",
    "  dfs.append(pd.read_csv('./smsspamcollection/'+file, sep='\\t',dtype=(str,str),\n",
    "                           names=[\"label\", \"message\"]))\n",
    "  \n",
    "messages_df = pd.concat(dfs,axis=0).reset_index(drop=True)\n",
    "\n",
    "messages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate dataset \n",
    "Lets check if there is any missing values or wrong values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     9652\n",
       "spam    1494\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check missing values in messages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, message]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(messages_df['label'].value_counts())\n",
    "print(\"check missing values in messages\")\n",
    "display(messages_df[messages_df['message'].isnull() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature engineering\n",
    "\n",
    "### Data Preprocessing\n",
    "Before building the classifier, we'll perform data cleaning and preprocessing steps. This includes tasks such as:\n",
    "\n",
    "- Mapping labels to binary values (0 for \"ham\", 1 for \"spam\").\n",
    "- Discarding messages that contain no alphanumeric characters.\n",
    "- Cleaning and transforming text data, including removing special characters, converting to lowercase, tokenization, removing stopwords, and lemmatization.\n",
    "\n",
    "### Feature Engineering\n",
    "We'll extract features from the text data to represent it in a format suitable for machine learning algorithms. Common feature engineering techniques for NLP tasks include TF-IDF (Term Frequency-Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "  # map labels into 0 and 1\n",
    "  df.label = df.label.map({'ham':0, 'spam':1})\n",
    "\n",
    "  # discard those messages which has no aplphbetic or numerical values\n",
    "  df['has_alphanumeric'] = df['message'].apply(lambda x: bool(re.search(r'[a-zA-Z0-9]', str(x))))\n",
    "  df = df[df['has_alphanumeric']].drop(columns=['has_alphanumeric'])\n",
    "  \n",
    "  # message cleansing\n",
    "  corpus = []\n",
    "  STOPWORDS = stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  for i in range(0, len(df)):\n",
    "    review = re.sub(r'[^a-zA-Z0-9]', ' ', df['message'].iloc[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in STOPWORDS]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    df.loc[df.index[i], 'cleaned_message'] = review\n",
    "\n",
    "\n",
    "  # Feature engineering\n",
    "  tfidf = TfidfVectorizer()\n",
    "  features= tfidf.fit_transform(corpus).toarray()\n",
    "  return features, df.label\n",
    "\n",
    "features, labels = data_preprocessing(messages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitting(features,labels):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(features,labels, test_size = 0.20, random_state = 0)\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation\n",
    "### Model Building\n",
    "We'll train and evaluate a `Multinomial Naive Bayes` model with an attention mechanism to handle the imbalance between \"ham\" and \"spam\" classes. The attention mechanism will allow the model to focus more on the minority class samples during training, leading to improved classification performance and more reliable outcomes.\n",
    "\n",
    "### Model Evaluation\n",
    "We'll evaluate the performance of each model using appropriate evaluation metrics such as accuracy, precision, recall, F1-score, and confusion matrix. Additionally, we'll use techniques such as hyperparameter tuning to optimize the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate a simple model:\n",
      "\n",
      "confusion_matrix  : \n",
      " [[1878   57]\n",
      " [   6  288]]\n",
      "accuracy  :  0.971736204576043\n",
      "precision  :  0.9754435471396843\n",
      "recall  :  0.971736204576043\n",
      "f1_score  :  0.9726753811792016\n",
      "\n",
      "\n",
      "hyperparameter tunning:\n",
      "\n",
      "best parameters are: ({'alpha': 0.1}, MultinomialNB(alpha=0.1, class_prior=[1.7318014540885018, 1.3409927295574904]))\n",
      "confusion_matrix  : \n",
      " [[1893   42]\n",
      " [   3  291]]\n",
      "accuracy  :  0.9798115746971736\n",
      "precision  :  0.9819906729736021\n",
      "recall  :  0.9798115746971736\n",
      "f1_score  :  0.9803366841921854\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, features, labels) -> None:\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = data_splitting(features, labels)\n",
    "        \n",
    "        # Convert classes to numpy array\n",
    "        classes = np.array([0, 1])\n",
    "        \n",
    "        # Compute class weights\n",
    "        class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=labels)\n",
    "        self.class_weights = {0: 1/class_weights[0], 1: 5/class_weights[1]}\n",
    "        \n",
    "        # Initialize model with class weights\n",
    "        self.model = MultinomialNB(class_prior=[self.class_weights[0], self.class_weights[1]])\n",
    "        \n",
    "    def train(self):\n",
    "        self.model = self.model.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(y_true=self.y_test, y_pred=y_pred)\n",
    "        precision = precision_score(y_true=self.y_test, y_pred=y_pred, average='weighted')\n",
    "        recall = recall_score(y_true=self.y_test, y_pred=y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true=self.y_test, y_pred=y_pred, average='weighted')\n",
    "        confusion_m = confusion_matrix(y_true=self.y_test, y_pred=y_pred)    \n",
    "        \n",
    "        return {\n",
    "            'confusion_matrix': confusion_m,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "    def hyperparameter_tuning(self,params):\n",
    "        # Define scoring metrics\n",
    "        scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "                    'precision': make_scorer(precision_score, average='weighted'),\n",
    "                    'recall': make_scorer(recall_score, average='weighted'),\n",
    "                    'f1_score': make_scorer(f1_score, average='weighted'),\n",
    "                    }\n",
    "        \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(estimator=self.model,\n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring=scoring,\n",
    "                                    refit='precision',\n",
    "                                    cv=5,\n",
    "                                    return_train_score=True)\n",
    "        \n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Get best parameters\n",
    "        self.best_params = grid_search.best_params_\n",
    "        \n",
    "        # Set model with best parameters\n",
    "        self.model = grid_search.best_estimator_\n",
    "\n",
    "        return self.best_params,self.model\n",
    "    \n",
    "model = Model(features, labels)\n",
    "print(\"Train and evaluate a simple model:\\n\")\n",
    "model.train()\n",
    "for key, value in model.evaluate().items():\n",
    "    if key == 'confusion_matrix':\n",
    "        print(key,\" : \\n\",value)\n",
    "    else:\n",
    "        print(key,\" : \",value)\n",
    "\n",
    "\n",
    "print(\"\\n\\nhyperparameter tunning:\\n\")\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]}\n",
    "best_params = model.hyperparameter_tuning(param_grid)\n",
    "print('best parameters are:', best_params)\n",
    "for key, value in model.evaluate().items():\n",
    "    if key == 'confusion_matrix':\n",
    "        print(key,\" : \\n\",value)\n",
    "    else:\n",
    "        print(key,\" : \",value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
